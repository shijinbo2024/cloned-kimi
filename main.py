import streamlit as st
from langchain.memory import ConversationBufferMemory

from utils import get_chat_response

st.title("ğŸ’¬ å°¤é¡ºAIåŠ©æ‰‹")

with st.sidebar:
    openai_api_key = st.text('''å°¤é¡ºæ˜¯æœåŠ¡å¤§ä¼—ä¿å§†ï¼Œæ˜¯äººç±»å¥åº·æŠ¤å£«ï¼Œæ˜¯ç”Ÿæ€ç¯å¢ƒçš„æ¸…æ´å·¥!
                                --è‘£äº‹é•¿å¥šå‹‡å…ˆç”Ÿ''')#è¿™å—åœ°æ–¹å¯ä»¥å†™æç¤ºè¯æ³¨æ„äº‹é¡¹ï¼Œå°±ä¸æ”¾å¯†ç äº†ï¼Œå‡å°‘ä½¿ç”¨é˜»ç¢

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„å°¤é¡ºAIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}]

for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input()
if prompt:
    if not openai_api_key:
        st.info("è¯·è¾“å…¥ä½ çš„OpenAI API Key")
        st.stop()
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)

    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
        response = get_chat_response(prompt, st.session_state["memory"],
                                     openai_api_key)
    msg = {"role": "ai", "content": response}
    st.session_state["messages"].append(msg)
    st.chat_message("ai").write(response)